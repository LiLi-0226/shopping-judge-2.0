import google.generativeai as genai

def get_verdict(api_key, model_name, product_a, product_b, system_instruction):
    """
    æ¥æ”¶å•†å“è³‡è¨Šèˆ‡äººæ ¼æŒ‡ä»¤ï¼Œå‘¼å« Geminiã€‚
    """
    # 1. è¨­å®š API
    genai.configure(api_key=api_key)
    
    # è¨­å®šç”Ÿæˆåƒæ•¸
    # âš ï¸ ä¿®æ­£ï¼šå°‡ token ä¸Šé™æé«˜åˆ° 8192ï¼Œé¿å…å›ç­”åˆ°ä¸€åŠè¢«åˆ‡æ‰
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 8192, 
    }
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = genai.GenerativeModel(
        model_name=model_name,
        generation_config=generation_config,
        system_instruction=system_instruction
    )

    # 3. å®šç¾© User Prompt
    # å„ªåŒ–ï¼šå¼·èª¿ã€Œè©³ç´°ã€èˆ‡ã€Œå®Œæ•´ã€ï¼Œé¿å… AI å·æ‡¶
    user_prompt = f"""
    è«‹å¯©åˆ¤ä»¥ä¸‹å…©å€‹å•†å“ï¼š

    ã€ğŸ“¦ é¸æ‰‹ A è³‡è¨Šã€‘ï¼š
    {product_a}
    
    --------------------
    
    ã€ğŸ“¦ é¸æ‰‹ B è³‡è¨Šã€‘ï¼š
    {product_b}
    
    ---
    ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼š
    è«‹å‹™å¿…éµå®ˆä½ çš„ã€Œè§’è‰²è¨­å®šã€èªæ°£ï¼Œä¸¦ç¢ºä¿å›ç­”**å®Œæ•´ä¸”è©³ç´°**ï¼Œä¸è¦ä¸­æ–·ã€‚
    è¼¸å‡ºçµæ§‹å¦‚ä¸‹ï¼š
    1. **âš–ï¸ ä¸€é‡è¦‹è¡€çŸ­è©•**ï¼šç”¨ä¸€å¥è©±ç¸½çµé€™å ´å°æ±ºã€‚
    2. **âš”ï¸ è¦æ ¼æ®˜é…·å°æ±ºè¡¨**ï¼šè«‹åˆ—å‡º**è©³ç´°çš„** Markdown è¡¨æ ¼ï¼Œæ¯”è¼ƒé—œéµå„ªç¼ºé»ã€è¦æ ¼æ•¸æ“šèˆ‡åƒ¹æ ¼ã€‚
    3. **ğŸ”¥ æœ€çµ‚åˆ¤æ±ºæ›¸**ï¼šè©³ç´°çš„åˆ†æèˆ‡å»ºè­°ï¼Œå­—æ•¸ä¸é™ï¼Œè«‹ç›¡æƒ…ç™¼æ®ä½ çš„æ¯’èˆŒ/ç†æ™ºè©•è«–ã€‚
    """

    # 4. ç™¼é€è«‹æ±‚
    chat = model.start_chat(history=[])
    response = chat.send_message(user_prompt)
    
    return response.text