import google.generativeai as genai

def get_verdict(api_key, model_name, product_a, product_b, system_instruction):
    """
    æ¥æ”¶å•†å“è³‡è¨Šèˆ‡äººæ ¼æŒ‡ä»¤ï¼Œå‘¼å« Geminiã€‚
    """
    # 1. è¨­å®š API
    genai.configure(api_key=api_key)
    
    # è¨­å®šç”Ÿæˆåƒæ•¸
    # token ä¸Šé™ç¶­æŒ 8192 ä»¥ç¢ºä¿å›ç­”å®Œæ•´
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 8192, 
    }
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = genai.GenerativeModel(
        model_name=model_name,
        generation_config=generation_config,
        system_instruction=system_instruction
    )

    # 3. å®šç¾© User Prompt
    # å„ªåŒ–ï¼šæ–°å¢ã€Œæœ¬åº­æœ€çµ‚è£æ±ºã€å€å¡Šï¼Œå¼·åˆ¶è¦æ±‚é¸æ“‡
    user_prompt = f"""
    è«‹å¯©åˆ¤ä»¥ä¸‹å…©å€‹å•†å“ï¼š

    ã€ğŸ“¦ é¸æ‰‹ A è³‡è¨Šã€‘ï¼š
    {product_a}
    
    --------------------
    
    ã€ğŸ“¦ é¸æ‰‹ B è³‡è¨Šã€‘ï¼š
    {product_b}
    
    ---
    ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼š
    è«‹å‹™å¿…éµå®ˆä½ çš„ã€Œè§’è‰²è¨­å®šã€èªæ°£ï¼Œä¸¦ç¢ºä¿å›ç­”**å®Œæ•´ä¸”è©³ç´°**ã€‚
    
    âš ï¸ **æœ€é«˜æŒ‡ä»¤ï¼šä½ å¿…é ˆå¹«ä½¿ç”¨è€…åšæ±ºå®šï¼ç¦æ­¢èªªã€Œçœ‹å€‹äººéœ€æ±‚ã€ã€ã€Œå…©è€…çš†å¯ã€é€™ç¨®å»¢è©±ã€‚** âš ï¸
    
    è¼¸å‡ºçµæ§‹å¦‚ä¸‹ï¼š
    1. **âš–ï¸ ä¸€é‡è¦‹è¡€çŸ­è©•**ï¼šç”¨ä¸€å¥è©±ç¸½çµé€™å ´å°æ±ºã€‚
    2. **âš”ï¸ è¦æ ¼æ®˜é…·å°æ±ºè¡¨**ï¼šè«‹åˆ—å‡ºè©³ç´°çš„ Markdown è¡¨æ ¼ï¼Œæ¯”è¼ƒé—œéµå„ªç¼ºé»ã€è¦æ ¼æ•¸æ“šèˆ‡åƒ¹æ ¼ã€‚
    3. **ğŸ”¥ æœ€çµ‚åˆ¤æ±ºæ›¸**ï¼šè©³ç´°çš„åˆ†æèˆ‡å»ºè­°ï¼Œç›¡æƒ…ç™¼æ®ä½ çš„æ¯’èˆŒ/ç†æ™ºè©•è«–ã€‚
    4. **ğŸ† æœ¬åº­æœ€çµ‚è£æ±º**ï¼š(éå¸¸é‡è¦) è«‹æ˜ç¢ºå®£å‘Šï¼šã€Œç²å‹è€…æ˜¯ [å•†å“åç¨±]ã€ã€‚è«‹æ ¹æ“šä½ çš„è§’è‰²æ€§æ ¼ï¼Œå¼·å‹¢åœ°æŒ‡å®šä¸€å€‹è´å®¶ï¼Œä¸¦çµ¦å‡ºæœ€å¾Œä¸€å€‹ç†ç”±å«æˆ‘è²·å®ƒã€‚
    """

    # 4. ç™¼é€è«‹æ±‚
    chat = model.start_chat(history=[])
    response = chat.send_message(user_prompt)
    
    return response.text